{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114354,
     "status": "ok",
     "timestamp": 1752063241865,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "uli0YfNhv4Qq",
    "outputId": "ed3d0984-039f-49a0-9f81-f47c7ada9689"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision tqdm timm detectors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import detectors\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyYdSAuxzIBu"
   },
   "source": [
    "### Retrieve Data and Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752063276735,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "B5tzmI0cwOZT"
   },
   "outputs": [],
   "source": [
    "def get_cifar10_data(batch_size):\n",
    "  \"\"\"Get CIFAR-10 data loaders with appropriate transforms\"\"\"\n",
    "  transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.49139968, 0.48215827 ,0.44653124],\n",
    "                         std=[0.24703233, 0.24348505, 0.26158768])\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    "  )\n",
    "  testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    "  )\n",
    "\n",
    "  trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                           shuffle=True, num_workers=2)\n",
    "  testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                          shuffle=False, num_workers=2)\n",
    "\n",
    "  return trainset, testset, trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752063279646,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "hgMix2CYyEqA"
   },
   "outputs": [],
   "source": [
    "def init_model(device):\n",
    "  '''\n",
    "  initialize vit tiny patch16_224 model from timm, no pretraining\n",
    "  '''\n",
    "  model = timm.create_model('vit_tiny_patch16_224',\n",
    "                            pretrained=False, num_classes=10)\n",
    "  model.to(device)\n",
    "  return model\n",
    "\n",
    "def get_teacher_model(device):\n",
    "  '''\n",
    "  get resnet18 teacher model from timm, with pretrained weights\n",
    "  '''\n",
    "  resnet18 = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
    "  #don't want to accidentally update params during training\n",
    "  for p in resnet18.parameters():\n",
    "    p.requires_grad = False\n",
    "  resnet18.to(device)\n",
    "  return resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBgPzA3IzSJ2"
   },
   "source": [
    "### Define eval and train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752063281428,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "9dvwflEiy7_U"
   },
   "outputs": [],
   "source": [
    "#accuracy of classification\n",
    "def eval_model(model, testloader, device):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      preds = outputs.argmax(dim=-1)\n",
    "      correct += preds.eq(labels).sum()\n",
    "      total += inputs.shape[0]\n",
    "  return correct / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1752063283566,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "_fZ6Kg0nzFOH"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "  model,\n",
    "  trainloader,\n",
    "  testloader,\n",
    "  device,\n",
    "  learning_rate,\n",
    "  weight_decay,\n",
    "  num_epochs,\n",
    "  teacher_model=None,\n",
    "  temperature=0.5,\n",
    "  alpha=0.5,\n",
    "  premature_stop=None):\n",
    "  optimizer = optim.AdamW(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "  ce_loss_criterion = nn.CrossEntropyLoss()\n",
    "  kld_loss_criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "  scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "  train_epoch_losses, train_epoch_acc, test_epoch_acc = [], [], []\n",
    "  epoch_values, iters, train_losses, train_acc = [], [], [], []\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "      #forward and backward pass\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      if teacher_model:\n",
    "        with torch.no_grad():\n",
    "          soft_labels = F.softmax(teacher_model(inputs) / temperature, dim=1) #get soft labels from teacher model\n",
    "        soft_preds = F.log_softmax(outputs / temperature, dim=1)\n",
    "        kld_loss = kld_loss_criterion(soft_preds, soft_labels) * (temperature ** 2)\n",
    "        ce_loss = ce_loss_criterion(outputs, labels)\n",
    "        loss = alpha * kld_loss + (1 - alpha) * ce_loss #combine CELoss and KL-Divergence Loss\n",
    "      else:\n",
    "        loss = ce_loss_criterion(outputs, labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      #update running statistics\n",
    "      total_loss += loss.item()\n",
    "      preds = outputs.argmax(dim=-1)\n",
    "      correct += preds.eq(labels).sum()\n",
    "      total += labels.size(0)\n",
    "      if premature_stop:\n",
    "        if batch_idx >= premature_stop: return total_loss, correct / float(total)\n",
    "\n",
    "      #update progress bar\n",
    "      pbar.set_postfix({\n",
    "        'Loss': f'{loss.item():.4f}',\n",
    "        'Acc': f'{100.*correct/total:.2f}%'\n",
    "      })\n",
    "      epoch_values.append(epoch)\n",
    "      iters.append(batch_idx)\n",
    "      train_losses.append(loss.item())\n",
    "      train_acc.append(correct / float(total))\n",
    "\n",
    "    # update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = total_loss / len(trainloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    test_acc = eval_model(model, testloader, device)\n",
    "\n",
    "    train_epoch_losses.append(epoch_loss)\n",
    "    train_epoch_acc.append(epoch_acc)\n",
    "    test_epoch_acc.append(test_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Train CELoss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "  results = {\n",
    "    'train_epoch_losses': train_epoch_losses,\n",
    "    'train_epoch_acc': train_epoch_acc,\n",
    "    'test_epoch_acc': test_epoch_acc,\n",
    "    'epoch_values': epoch_values,\n",
    "    'iters': iters,\n",
    "    'train_losses': train_losses,\n",
    "    'train_acc': train_acc\n",
    "  }\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752063288153,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "NuB7DEeazhuf"
   },
   "outputs": [],
   "source": [
    "def save_stats(results, output_file_prefix, ts):\n",
    "  #save batch-level stats\n",
    "  with open(f'/content/drive/My Drive/ML + Robotics/{output_file_prefix}_batchstats_{ts}.csv', 'w') as f:\n",
    "    for i in range(len(results['train_losses'])):\n",
    "      row = f'''{results['epoch_values'][i]},{results['iters'][i]},{results['train_losses'][i]},{results['train_acc'][i]}\\n'''\n",
    "      f.write(row)\n",
    "\n",
    "  #save epoch-level stats\n",
    "  with open(f'/content/drive/My Drive/ML + Robotics/{output_file_prefix}_epochstats_{ts}.csv', 'w') as f:\n",
    "    for i in range(len(results['train_epoch_losses'])):\n",
    "      row = f'''{i},{results['train_epoch_losses'][i]},{results['train_epoch_acc'][i]},{results['test_epoch_acc'][i]}\\n'''\n",
    "      f.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8jEfbuuzVnA"
   },
   "source": [
    "### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8813,
     "status": "ok",
     "timestamp": 1752063309809,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "9E5LkH4NyKTS",
    "outputId": "1a51919e-276c-4417-82df-19cfa5462c90"
   },
   "outputs": [],
   "source": [
    "#define compute device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('running using', device)\n",
    "\n",
    "#get data\n",
    "trainset, testset, trainloader, testloader = get_cifar10_data(128)\n",
    "\n",
    "#get teacher model\n",
    "resnet_teacher = get_teacher_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492005,
     "status": "ok",
     "timestamp": 1751857281136,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "mfYwIVhcyREq",
    "outputId": "033121d9-1485-4f0f-f62e-92e2421cfe33"
   },
   "outputs": [],
   "source": [
    "#find best initial learning rate for vit_normal\n",
    "lr_tests = []\n",
    "for lr in (torch.rand(20) * 1e-2):\n",
    "  model = init_model(device)\n",
    "  loss, acc = train(model, trainloader, testloader,\n",
    "                    device, learning_rate=lr.item(), weight_decay=1e-2,\n",
    "                    num_epochs=1, premature_stop=50)\n",
    "  lr_tests.append((lr.item(), loss, acc))\n",
    "\n",
    "#see acc-maximizing learning rate\n",
    "sorted(lr_tests, key=lambda x: x[2].item(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2024520,
     "status": "ok",
     "timestamp": 1752030615080,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "_JJbd9af1jog",
    "outputId": "b65878ef-9017-4f43-da85-516c4a740a68"
   },
   "outputs": [],
   "source": [
    "#find best initial learning rate, temp, and alpha for vit_student\n",
    "lr_tests = []\n",
    "for i in range(20):\n",
    "  model = init_model(device)\n",
    "  lr = torch.rand(1).item() * 1e-2\n",
    "  temp, alpha = torch.rand(1).item(), torch.rand(1).item()\n",
    "  loss, acc = train(model, trainloader, testloader,\n",
    "                    device, learning_rate=lr, weight_decay=1e-2,\n",
    "                    num_epochs=1, teacher_model=resnet_teacher,\n",
    "                    temperature=temp, alpha=alpha, premature_stop=50)\n",
    "  lr_tests.append((lr, temp, alpha, loss, acc))\n",
    "\n",
    "#acc maximizing lr, temp, alpha\n",
    "sorted(lr_tests, key=lambda x: x[-1].item(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1752069550906,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "BUytnnORyWjd",
    "outputId": "10ad6009-247f-490c-a048-5a84c1090934"
   },
   "outputs": [],
   "source": [
    "#initialize models\n",
    "vit_normal = init_model(device)\n",
    "vit_student = init_model(device)\n",
    "resnet_teacher = get_teacher_model(device)\n",
    "\n",
    "vit_param_count = sum([p.numel() for p in vit_normal.parameters()])\n",
    "resnet_param_count = sum([p.numel() for p in resnet_teacher.parameters()])\n",
    "print(f'vit_normal and vit_student parameter count: {vit_param_count:,}')\n",
    "print(f'resnet18 teacher parameter count: {resnet_param_count:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19464,
     "status": "ok",
     "timestamp": 1752064402628,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "zDcjfpXuy03m",
    "outputId": "ee8ecd82-e9d6-42db-e762-09b95ab037b3"
   },
   "outputs": [],
   "source": [
    "#show initial performance of model before training\n",
    "print('evaluating accuracy of default parameters on CIFAR10 test set...')\n",
    "acc = eval_model(vit_normal, testloader, device)\n",
    "print(f'initial accuracy {acc:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752069545838,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "jvPkXzVEyjYP"
   },
   "outputs": [],
   "source": [
    "#define hyperparams/training constants across both models\n",
    "WEIGHT_DECAY = 1e-2\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2081334,
     "status": "ok",
     "timestamp": 1752067123629,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "mnsTqO8LSjBc",
    "outputId": "ee5cc160-ea50-4376-bf11-a2b344d746b5"
   },
   "outputs": [],
   "source": [
    "#learning_rate = 4e-3\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#train vit_normal, store results\n",
    "print('training vit using normal pre-training approach')\n",
    "vit_normal_results = train(\n",
    "  vit_normal,\n",
    "  trainloader,\n",
    "  testloader,\n",
    "  device,\n",
    "  learning_rate=learning_rate,\n",
    "  weight_decay=WEIGHT_DECAY,\n",
    "  num_epochs=NUM_EPOCHS)\n",
    "ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_stats(vit_normal_results, 'vit_normal', ts)\n",
    "torch.save(vit_normal.state_dict(), f'/content/drive/My Drive/ML + Robotics/vit_normal_{ts}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3990734,
     "status": "ok",
     "timestamp": 1752073545071,
     "user": {
      "displayName": "Jacob Dunning",
      "userId": "17361546069656016098"
     },
     "user_tz": 360
    },
    "id": "JHfFJpVbSl33",
    "outputId": "2f1ae617-aaee-42b5-e57f-f3ce7e78133c"
   },
   "outputs": [],
   "source": [
    "student_learning_rate = 1e-4\n",
    "temperature = 0.212\n",
    "alpha=0.62\n",
    "\n",
    "#use train vit_student with teacher model\n",
    "print('training vit using distillation/student-teacher approach')\n",
    "vit_student_results = train(\n",
    "  vit_normal,\n",
    "  trainloader,\n",
    "  testloader,\n",
    "  device,\n",
    "  learning_rate=student_learning_rate,\n",
    "  weight_decay=WEIGHT_DECAY,\n",
    "  num_epochs=NUM_EPOCHS,\n",
    "  teacher_model=resnet_teacher,\n",
    "  temperature=temperature,\n",
    "  alpha=alpha)\n",
    "ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_stats(vit_student_results, 'vit_student', ts)\n",
    "torch.save(vit_student.state_dict(), f'/content/drive/My Drive/ML + Robotics/vit_normal_{ts}.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO8wQqmKTc2FxHGi+OJKDcQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
